The bidding strategy we chose, is not a static strategy, but is time dependent. The strategy is divided in three different phases, with each phase using its own sub-strategy. The main \texttt{Group7\_BS} class decides the current phase by evaluating the normalized time (\texttt{getTime()}) and the two hard-coded phase thresholds, which are corrected for discounts and are stored in the array \texttt{phaseBoundary}. 
The phases itself are all subclasses of the \verb-Phase- class. In this section we discuss the strategy behind each of the phases separately. Note that, because we wanted our acceptance strategy and our opponent model (strategy) to 
work together, we have used a helper class (\verb-Helper-) as the BOA framework did not provide each component with references to all other components. Using the helper class, we can also share values, like the Kalai point, among all our components in order to save computation time and to allow other components to have access to otherwise unavailable information. In case our components are used separately, we ensure that we always have fall back values whenever we request a certain value from the helper class which could be unavailable, since the component that sets that value might be unavailable.

\subsubsection{First Phase}
By offering an opening bid of maximal utility, the opponent can easily estimate our preference profile. Due to this reason we have chosen to offer an initial bid of utility $1.0$ (lower values sometimes lead to bad results where this bid is extremely good for our opponent and is directly accepted).\\ 

After determining our opening bid and receiving the initial bid from the opponent, our agent continues by generating random bids. These random bids are generated within a small utility range (measured by our utility) given by the \verb-getBidRange-. The center of this range decreases by a small amount when time passes.
The center is first set to $1.0$, and ends at $0.9$ (the lower bound). The lowerbound is set to $0.9$, except when our opponent best bid is closer than $0.1$ to $0.9$ utility (in our utility scale). If this is the case the lower bound is set to the utility of this bid of the opponent $+0.1$, and we ensure that the lowerbound and upperbound do not overlap. The width of the range is set to  $0.02$. 

We do this, because we think that if the opponent can estimate our preference profile better,
we can reach better win-win situations. By conseding this way, we ensure that most opponent 
models accurately profile our preferences.

\subsubsection{Second Phase}

For phase $2$ we decided to implement the \emph{Tit-for-Tat} strategy \cite{titfortat}.
We chose this because it works fairly well against different agents, since you will play
hard against hardheaded opponents and more nice against conceding agents.
However, as noted in the referenced paper, we should not play too nice,
and try to exploit other opponents. We use the following strategy. \\

We use the distance to the \emph{Kalai-Smorodinsky} point as reference to calculate
the amount of concession for both the opponent as our own agent. When conceding, we aim for this point. We chose this point because we think it is the most fair since for this point
our utility is equal to the utility of the opponent.
We decided to use the distance to this point instead of only relying on our own utility 
or opponent estimated utilities, because when we look at these values we can hardly see whether or not our opponent is conceding: conceding opponents tend to vary a lot on the scale of our utility,
and utility estimates for the opponent are so noise one at least needs to average over more than 100 bids. So instead, we use the distance to the KS and this improves the detection of concessions,
since it relies on both the opponent model and our own utility estimates. \\

We average the change in distance (\verb-getAvgDifferenceKS-) of the last five bids to the Kalai-Smorodinsky point to determine the mean concession of the opponent. We
multiply this by a factor $\sfrac{1}{3}$, and then match their concession by walking towards the KS point. We multiply by this factor to avoid conceding too much in the direction of the opponent. 
We normalize every distance by taking the distance from the Kalai point to the best bid point of our agent and the opponent. We do a lineair interpolation between the best bid and the 
Kalai point (\verb-interpolateBidPoints-).
\\

Furthermore, to ensure our agent does not get stuck when playing against 
another Tit-for-Tat agent, we will randomly concede from time to time. 
These concessions are done towards the Kalai-Smorodinsky point, and linearly over 
$10$ bids, so the opponent can detect our concession more accurately. When the concession has been done, we hope the opponent matches  our concession. If the opponent has done this, we will approach him using Tit-for-Tat, but if not, we take our concession back. \\

Finally, we want to reach the most efficient outcomes. Because of this,
we will randomly offer bids on the \emph{Pareto Frontier} $50\%$ of the time (\verb-FindClosestParetoBidPoint()-).
However, to select this bid, we take the Pareto bid closest to our current bid in a special sense.
When determining the closest bid, we weigh our utility twice as much
as the opponent utility (\verb-interpolateBidPoints-), to ensure we don't concede too much by accident 
(this can happen when dealing with strange pareto frontiers).

\subsubsection{Third Phase}

The third phase only consists of the very last part of the negotiation session (usually from $t=0.95$). The strategy that is employed here offers bids that are decreasing when time elapses towards the end of the negotiation session, also the approximated opponent model strategy is used from our method \texttt{getOpponentModel()} in the OMS. \\

When this method returns that the opponent behaves as \emph{conceder} (\verb-ourHelper.getOMStrategy().getOpponentModel();-) then our agent chooses the best from two possibilities; the \emph{Kalai-Smodorinsky} point and the generated bid that decreases over time. When the opponent is assumed to be \emph{hardheaded}, then we just use the latter one. When this utility $u$ is determined we choose the best bid within the range $[u-0.01, u+0.01]$. Choosing the best bid is done by fetching all possible bids within this utility range and choosing the one that is best for the opponent by exploiting the information from our opponent model. This of course, increases the probability that the opponent accepts our bid. \\

Finding the best bid within the calculated utility range is not garantueed to succes, therefore we have also implemented a fallback mechanism. When determining the next bid has been tried for $15$ times, then a fallback bid is randomly chosen from already offered bids. This way we are sure that a bid is offered without wasting too much time.

