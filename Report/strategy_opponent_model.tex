Our opponent model is based on the standard frequency model, but has some tweaks that attempt to improve the quality of the model. The issue weight estimation is still equal to the standard frequency model method. The difference is in the way we approximate values of the items within an issue. The improvement is based on the idea that if the opponent does a new, previously unseen, bid, that this is probably close in utility to the other bids we've seen. This is implemented by changing the so-called learn value addition based on how ``wrong'' our opponent model is for the current bid. 

In order to estimate how ``wrong'' the estimate is, we first need to decide what offer we expect from the opponent. To do this we make the assumption that new offers the opponent makes are always close to old offers, but usually a bit lower. We also assume that the opponent's utility space has a normal distribution with a mean around $\mu = 0.5$, and a variance around $\sigma^2 = 0.02$. These values have been determined by examining some domains that were present in genius. The expected utility of a bid is calculated when we receive a bid we haven't received before from the opponent. We then look at how many distinct bids we have received ($D$) and what the size of the utility space is (the total number of bids possible, called $T$). We also approximate the average number of bids ignored by the opponent ($I$). We then use the quantile function of the normal distribution to calculate the expected utility:
\begin{equation}
  E(U) = \text{normcdf}^{-1} (\frac{D \cdot I}{T}) = \mu + \sigma \sqrt{2} \text{erf}^{-1} (2 \frac{D \cdot I}{T} - 1)
\end{equation}
Where $\text{erf}^{-1}(x)$ is the inverse error function. We save this expected utility for each bid and when we receive it again 