% !TEX root = negotation_final_report.tex
After designing and implementing our agent the BOAconstructor it is time to put it to the test in various situations. In the next two subsections we quantify the performance of our agent. 
We will let our agent compete against various agents from \texttt{ANAC 2011}, we will test the influence of different acceptance strategies for our agent,
we quantify how much our opponent model improves our results, and finally test it on a wide range of domains with and without discounted utilities.
We present the results and discuss the efficiency of the agent in terms of reaching \emph{Nash solutions}, \emph{Kalai Smorodinski points} and outcomes that lie on the \emph{Pareto Optimal Frontier} (POF).

\subsection{Performance against \texttt{ANAC 2011} agents}

In this part we compare our agent to three of the agents that attended in the ANAC 2011 competitio: \emph{HardHeaded}, \emph{Gahboninho} and \emph{The Negotiatior}. The results have been obtained by running a tournament using multiple utility profiles for the (undiscounted) Party domain and setting the negotiation time to $30$ seconds,
we use these same settings for further testing also unless otherwise specified. \\

\begin{table}
	\centering
	\small
    \begin{tabular}{l|p{2cm}|p{2cm}|p{2cm}|p{2cm}|p{2cm}|p{2cm}|}
    ~                                    & Average Time Agreement & Average Discounted Util & Average Dist. to Nash & Average Dist. to Pareto & Average Dist. to Kalai \\
    \hline
    \emph{HardHeaded}		& 0.858  & 0.927  & 0.102  & 0.017  & 0.084   \\ \hline
    \emph{Gahboninho}   	& 0.887  & 0.918  & 0.032  & 0.001  & 0.035   \\ \hline
    \emph{The Negotiator} 	& 0.725  & 0.871  & 0.050  & 0.003  & 0.052   \\ \hline
    \emph{Self}                 & 0.823  & 0.877  & 0.061  & 0.007  & 0.057   \\ \hline
    \end{tabular}
    \caption{Performance of our agent against \texttt{ANAC 2011} agents (Runtime: $30$s) \label{table:anac2011-results}}
\end{table}

From the results in Table~\ref{table:anac2011-results} we notice we rank third on average utility. 
We notice that HardHeaded and Gahboninho beat us in utility, with a difference of at least $0.04$. The times to agreement for these agents is also higher,
indicating that our agent might accept bids too fast or is conceding too fast in the last phase.
Regarding the effiency of the negotiation we observe that the average distance to the POF, Nash and Kalai upon agreement is very small,
which is a very desirable propoerty for our agent. 

\subsection{Performance of our acceptance strategy}

The next test consists of running our agent with varying \emph{acceptance strategies}. We perform those test so we are able to compare our acceptance strategy with other available ones (our strategy is discussed in Section~\ref{sec:strategyAS}). Again these tests are performed by starting a small tournament. The results are displayed in the Table~\ref{table:as-results}. \\

\begin{table}
	\centering
\begin{tabular}{l|lll}
Agent                         & \begin{tabular}[c]{@{}c@{}}Average\\   time to agreement\end{tabular} & \begin{tabular}[c]{@{}c@{}}Percentage\\   of agreement\end{tabular} & \begin{tabular}[c]{@{}c@{}}Average\\   utility\end{tabular} \\ \hline
Our Acceptance Strategy       & 0.777                                                                 & 100 $\%$                                                             & 0.870                                                       \\ \hline
Nice-Tit-For-Tat              & 0.867                                                                 & 100 $\%$                                                             & 0.866                                                       \\ \hline
Agent K2                      & 0.865                                                                 & 97 $\%$                                                             & 0.865                                                       \\ \hline
IAMHaggler2011                & 0.633                                                                 & 97 $\%$                                                             & 0.865                                                       \\ \hline
Other - Time \{t=0.99\}       & 0.837                                                                 & 100 $\%$                                                             & 0.855                                                       \\ \hline
Other - False                 & 0.851                                                                 & 94 $\%$                                                             & 0.855                                                       \\ \hline
Other - Next \{a=1.0. b=0.0\} & 0.873                                                                 & 94 $\%$                                                              & 0.847                                                       \\ \hline
Other - Constant \{c=0.9\}    & 0.592                                                                 & 91 $\%$                                                              & 0.814                                                       \\ \hline
The Negotiator                & 0.862                                                                 & 100  $\%$                                                            & 0.743                                                       \\ \hline
BRAMAgent                     & 0.847                                                                 & 100 $\%$                                                             & 0.729                                                       \\ \hline
HardHeaded                    & 0.923                                                                 & 75 $\%$                                                              & 0.680                                                      
\end{tabular}
\caption{Performance of acceptance strategy compared with other acceptance strategies for our agent (Runtime: $30$s) \label{table:as-results}}
\end{table}

We note that combined with our bidding strategy and our opponent model, our acceptance strategy results in the highest average utility.
The nice-tit-for-tat strategy is performing best after our acceptance strategy, just performing slightly worse with $0.004$ difference in average utility.
So, our acceptance strategy is performing better, however the performance is not really significantly higher.
We note our acceptance strategy always reaches an agreement (just as tit-for-tat).
Finally, we note our acceptance strategy is one of the fastest strategy to accept, which indicates our agent might accept bids too fast.

\subsection{Performance of our opponent model}
To test if our opponent model is better than the default hardheaded frequency model, we ran the performance test against the ANAC 2011 agents using the hardheaded frequency model. The results of this are shown in \autoref{table:anac2011-hh}.
\begin{table}[H]
	\centering
	\small
    \begin{tabular}{l|p{2cm}|p{2cm}|p{2cm}|p{2cm}|p{2cm}|p{2cm}|}
    ~              & Average Time Agreement & Average Discounted Util & Average Dist. to Nash & Average Dist. to Pareto & Average Dist. to Kalai \\
    \hline
    \emph{HardHeaded}		& 0.883  & 0.916  & 0.166  & 0.055  & 0.152   \\ \hline
    \emph{Gahboninho}   	& 0.881  & 0.848  & 0.116  & 0.020  & 0.097   \\ \hline
    \emph{The Negotiator} 	& 0.756  & 0.868  & 0.092  & 0.027  & 0.079   \\ \hline
    \emph{Self}                 & 0.839  & 0.806  & 0.125  & 0.035  & 0.140   \\ \hline
    \end{tabular}
    \caption{Performance of our agent with \texttt{HardHeaded Frequency Modeling} (Runtime: $30$s) \label{table:anac2011-hh}}
\end{table}
We see that, compared to our own opponent model, the average utility has decreased by $0.071$, which means that our opponent model leads to  better results for our agents. 
Furthermore, we see that the average utilities for the opponent are also lower compared to what our opponent model achieved.
The distance to the \emph{Nash point}, \emph{Pareto Frontier} and \emph{Kalai point} are especially interesting for evaluating the quality of the opponent model: a better opponent model allows us to offer bids closer to these optimal values. We also note here that for every agent these properties are lowest using our own opponent model.

\subsection{Performance In Different Domains}
In order to test whether our agent can cope with different domains, we tested it against the same selection of 2011 agents, but using different domains. More specifically, the test was run in the Car/ADG domain, the Amsterdam party domain, the Camera domain, the Nice Or Die domain, the Grocery domain, the IS BT Acquisition  domain, and the Laptop domain. The average results for all agents are shown in \autoref{table:anac2011-domains}.
\begin{table}[H]
  \centering
  \small
  \begin{tabular}{l|p{2cm}|p{2cm}|p{2cm}|p{2cm}|p{2cm}|}
    ~                     & Average Time Agreement & Average Discounted Util & Average Dist. to Nash & Average Dist. to Pareto & Average Dist. to Kalai \\
    \hline
    \emph{HardHeaded}     & 0.807 & 0.750 & 0.142 & 0.032 & 0.150 \\ \hline
    \emph{Gahboninho}     & 0.731 & 0.807 & 0.065 & 0.004 & 0.165 \\ \hline
    \emph{The Negotiator} & 0.694 & 0.646 & 0.288 & 0.000 & 0.220 \\ \hline
    \emph{Self}           & 0.744 & 0.712 & 0.165 & 0.012 & 0.179 \\ \hline
  \end{tabular}
 \caption{Performance of our agent using a set of diverse domains (Runtime: $30$s) \label{table:anac2011-domains}}
\end{table}
We note that in these domains the average utility of all agents is significantly lower compared to the party domain used in the other tests. We also see that the difference between the utilities is now more significant: the difference between the best and worst average utility is now almost 0.15, whereas this difference was 0.05 for the party domain. 

In order to analyze these results further we decided to create a table in which we compare the average discounted utility in each domain. This allows us to compare the differences per domain. 

The Car domain has a Pareto frontier that allows for high utilities for both agents. As we see in \autoref{table:anac2011-domains2}, most agents seem to exploit this fact well. What is interesting to see is that our agent has the worst average utility for this domain. This is possibly caused by us exploring utilities 0.9 to 1.0 during the initial phase. Enemies will probably not except bids that are worse then what we already offered which leads to us losing in the car domain.

In the Amsterdam Party domain, the average utilities are very close together. The utility space has what looks like a normal distribution for both parties, which means that our agent should be able to construct a reliable opponent model. 

The camera domain has a utility space that is a bit skewed towards low utilities. This is what causes the average utilities to be lower. However, since our strategy attempts to move towards the Kalai point, we can exploit spaces where the best option is not close to the optimal option for both players, leading to a higher average utility.

The nice or die domain has only 3 possible bids: if both players concede, they get a utility of 0.3, but if only one of them concedes the utility is good for the other player, but bad for the first one. We see that The Negotiator always concedes to what is best for the other players, while HardHeaded and Gahboninho are more conservative. Since our model accepts the opponent's bid if the time has almost run out, we have a lower average utility here.

The grocery domain also has what looks like a Gaussian distribution of it's utilities over the bids and a Pareto frontier that is located away from $1.0$ utility for both players. In other words: it's similar to the camera domain. This caused us to have a better utility in this domain.

The LS BT Acquisition domain is concentrated at the higher utilities: all possible bids have a utility of $0.65$ or higher for both players. This probably caused our opponent model to be inaccurate, which in turn leads to a wrong approximation the Kalai-point. We think this caused us to accept offers that were in fact not very good.

The laptop domain is very small and has only two bids on the Pareto frontier. The domain is laid out in such a way that conceding almost immediately leads to unfortunate bids, which makes it hard to get to the optimal agreement. This is probably what caused problems in our solution.

\begin{table}[H]
  \centering
  \small
  \begin{tabular}{l|p{2.5cm}|p{2.5cm}|p{2.5cm}|p{2.5cm}|}
			    & HardHeaded     & Gahboninho     & The Negotiator & Self \\ \hline
  Car                       & \textbf{0.972} & 0.923          & 0.960          & 0.893 \\ \hline
  Amsterdam Party           & \textbf{0.850} & 0.843          & 0.808          & 0.834 \\ \hline
  Camera                    & 0.766          & 0.698          & 0.732          & \textbf{0.777} \\ \hline
  Nice or Die               & 0.500          & \textbf{1.000} & 0.160          & 0.413 \\ \hline
  Grocery                   & 0.689          & 0.705          & 0.572          & \textbf{0.758} \\ \hline
  IS BT Acquisition         & 0.762          & \textbf{0.809} & 0.803          & 0.683 \\ \hline
  Laptop                    & \textbf{0.711} & 0.673          & 0.489          & 0.627 \\ \hline
  \end{tabular}
  \caption{Average discounted utilities of the tested agents in the given domains (Runtime: $30$s) \label{table:anac2011-domains2}}
\end{table}

In order to check whether taking discounts into account improved the results, we ran another test where the length of the phases in the bidding strategy were adjusted automatically. This lead to the results in \autoref{table:anac2011-domains3}. As we see, the differences are very similar or worse for our agent compared to keeping the same phases for all possible discount vectors. Therefore we decided to ignore the discount factors in our agent.

\begin{table}[H]
  \centering
  \small
  \begin{tabular}{l|p{2.5cm}|p{2.5cm}|p{2.5cm}|p{2.5cm}|}
                            & HardHeaded     & Gahboninho & The Negotiator & Self \\ \hline
  Camera                    & 0.767          & 0.703          & 0.732          & \textbf{0.773} \\ \hline
  Grocery                   & 0.685          & 0.705          & \textbf{0.756} & 0.732          \\ \hline
  IS BT Acquisition         & 0.759          & \textbf{0.814} & 0.804          & 0.688          \\ \hline
  Laptop                    & \textbf{0.713} & 0.673          & 0.488          & 0.627          \\ \hline
  \end{tabular}
  \caption{Average discounted utilities of the tested agents in the given domains with phases scaled to bidding discount (Runtime: $30$s) \label{table:anac2011-domains3}}
\end{table}
